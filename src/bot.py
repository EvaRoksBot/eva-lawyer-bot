import os
import tempfile
import logging
import shutil
import subprocess
from dotenv import load_dotenv

from docx import Document
from pdf2image import convert_from_bytes
import pytesseract

from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import (
    Application, MessageHandler, CallbackQueryHandler, CommandHandler,
    ContextTypes, filters,
)

from openai import OpenAI

load_dotenv()
log_level = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=getattr(logging, log_level, logging.INFO))
log = logging.getLogger("eva-lawyer-bot")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or os.getenv("AI_API_KEY", "")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN") or os.getenv("TELEGRAM", "")
AI_BASE_URL = os.getenv("OPENAI_BASE_URL") or os.getenv("AI_BASE_URL")
AI_MODEL = os.getenv("AI_MODEL", "gpt-4o-mini")

if not TELEGRAM_BOT_TOKEN:
    raise RuntimeError("ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ TELEGRAM_BOT_TOKEN Ð¸Ð»Ð¸ TELEGRAM (Ñ‚Ð¾ÐºÐµÐ½ Ð±Ð¾Ñ‚Ð°).")
if not OPENAI_API_KEY:
    raise RuntimeError("ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ OPENAI_API_KEY Ð¸Ð»Ð¸ AI_API_KEY (ÐºÐ»ÑŽÑ‡ Ð˜Ð˜).")

client = OpenAI(api_key=OPENAI_API_KEY, base_url=AI_BASE_URL) if AI_BASE_URL else OpenAI(api_key=OPENAI_API_KEY)

SYSTEM_PROMPT = (
    "Ð¢Ñ‹ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ‡Ñ‘Ñ‚ÐºÐ¾ Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾. "
    "Ð•ÑÐ»Ð¸ Ð½Ðµ Ñ…Ð²Ð°Ñ‚Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…, ÑƒÐºÐ°Ð¶Ð¸, Ñ‡Ñ‚Ð¾ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ. Ð¯Ð·Ñ‹Ðº Ð¾Ñ‚Ð²ÐµÑ‚Ð°: Ñ€ÑƒÑÑÐºÐ¸Ð¹."
)


def _llm(prompt: str) -> str:
    resp = client.chat.completions.create(
        model=AI_MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
        max_tokens=800,
    )
    return resp.choices[0].message.content or ""


def _build_task_prompt(task: str, text: str) -> str:
    if task == "analyze_contract":
        return (
            "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€. Ð’Ñ‹Ð´ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚, Ð¾Ð±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸, Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ, "
            "ÑˆÑ‚Ñ€Ð°Ñ„Ñ‹, Ñ€Ð¸ÑÐºÐ¸, ÑÐ¿Ð¾ÑÐ¾Ð±Ñ‹ Ð·Ð°Ñ‰Ð¸Ñ‚Ñ‹.\n\nÐ¢ÐµÐºÑÑ‚:\n" + text
        )
    if task == "risk_table":
        return (
            "Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ñ€Ð¸ÑÐºÐ¾Ð²: Ð Ð¸ÑÐº | Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ | Ð’Ð»Ð¸ÑÐ½Ð¸Ðµ | ÐœÐ¸Ñ‚Ð¸Ð³Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ðµ Ð¼ÐµÑ€Ñ‹."\
            "\n\nÐ¢ÐµÐºÑÑ‚:\n" + text
        )
    if task == "verify_dd":
        return (
            "Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐ¹ Ñ‡ÐµÐº-Ð»Ð¸ÑÑ‚ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÐºÐ¾Ð½Ñ‚Ñ€Ð°Ð³ÐµÐ½Ñ‚Ð° (Due Diligence) Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚ÐµÐºÑÑ‚Ð°."\
            "\n\nÐ¢ÐµÐºÑÑ‚:\n" + text
        )
    if task == "court_search":
        return (
            "Ð¡Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐ¹ Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð½Ð¾Ñ€Ð¼Ñ‹/Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÑƒ, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼."\
            "\n\nÐ¢ÐµÐºÑÑ‚:\n" + text
        )
    if task == "analyze_claim":
        return (
            "ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒ Ñ‡ÐµÑ€Ð½Ð¾Ð²Ð¸Ðº Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½Ð° Ð¿Ñ€ÐµÑ‚ÐµÐ½Ð·Ð¸ÑŽ Ñ Ð¾Ð¿Ð¾Ñ€Ð¾Ð¹ Ð½Ð° Ñ‚ÐµÐºÑÑ‚."\
            "\n\nÐ¢ÐµÐºÑÑ‚:\n" + text
        )
    return "Ð¡ÑƒÐ¼Ð¼Ð°Ñ€Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ:\n\n" + text


async def ocr_pdf_bytes(file_bytes: bytes) -> str:
    try:
        images = convert_from_bytes(file_bytes)
    except Exception as e:
        return f"[OCR] ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ PDF (poppler?): {e}"
    parts = []
    for i, image in enumerate(images, 1):
        try:
            txt = pytesseract.image_to_string(image, lang="rus+eng")
        except pytesseract.TesseractNotFoundError:
            return "[OCR] ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¸Ðº tesseract-ocr Ð² ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ðµ."
        except Exception as e:
            txt = f"[OCR] ÐžÑˆÐ¸Ð±ÐºÐ° Ð½Ð° ÑÑ‚Ñ€. {i}: {e}"
        parts.append(f"\nÐ¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {i}:\n{txt}")
    return "\n".join(parts).strip()


def read_docx_bytes(file_bytes: bytes) -> str:
    """Extract text content from DOCX bytes.

    The bytes are written to a temporary file for processing via
    ``python-docx``. The temporary file is removed afterwards to avoid
    leaving artifacts on disk.
    """
    with tempfile.NamedTemporaryFile(suffix=".docx", delete=False) as tmp:
        tmp.write(file_bytes)
        tmp.flush()
        tmp_path = tmp.name

    try:
        doc = Document(tmp_path)
        chunks = [p.text for p in doc.paragraphs if p.text]
        for table in doc.tables:
            for row in table.rows:
                cells = [cell.text.strip() for cell in row.cells]
                chunks.append(" | ".join(cells))
        return "\n".join(filter(None, chunks)).strip()
    finally:
        os.unlink(tmp_path)


def read_txt_bytes(file_bytes: bytes) -> str:
    try:
        return file_bytes.decode("utf-8", errors="replace").strip()
    except Exception:
        return file_bytes.decode("cp1251", errors="replace").strip()


def cut_telegram(text: str, limit: int = 4000) -> str:
    if len(text) <= limit:
        return text
    return text[: limit - 50] + "\nâ€¦(Ð¾Ð±Ñ€ÐµÐ·Ð°Ð½Ð¾)"


async def cmd_diag(update: Update, _):
    bins = {
        "tesseract": shutil.which("tesseract"),
        "pdftoppm": shutil.which("pdftoppm"),
    }
    env_ok = bool(OPENAI_API_KEY and TELEGRAM_BOT_TOKEN)
    try:
        tver = subprocess.check_output(["tesseract", "--version"], text=True).splitlines()[0]
    except Exception as e:
        tver = f"err: {e}"
    msg = (
        f"âœ… ENV: {env_ok}\n"
        f"ðŸ”‘ AI key: {bool(OPENAI_API_KEY)} | ðŸ¤– TG token: {bool(TELEGRAM_BOT_TOKEN)}\n"
        f"ðŸ§  Model: {AI_MODEL}\n"
        f"ðŸ“¦ Binaries: {bins}\n"
        f"ðŸ–¹ tesseract: {tver}\n"
    )
    await update.message.reply_text(cut_telegram(msg))


MAX_INPUT_CHARS = 18000


async def handle_any_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.document:
        return
    doc = update.message.document
    name = (doc.file_name or "").lower()
    mime = (doc.mime_type or "").lower()

    tg_file = await doc.get_file()
    file_bytes = await tg_file.download_as_bytearray()

    if "pdf" in mime or name.endswith(".pdf"):
        await update.message.reply_text("Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ PDFâ€¦")
        context.user_data["extracted_text"] = await ocr_pdf_bytes(bytes(file_bytes))
    elif "wordprocessingml" in mime or name.endswith(".docx"):
        await update.message.reply_text("Ð§Ð¸Ñ‚Ð°ÑŽ .docxâ€¦")
        context.user_data["extracted_text"] = read_docx_bytes(bytes(file_bytes))
    elif mime.startswith("text/") or name.endswith(".txt"):
        await update.message.reply_text("Ð§Ð¸Ñ‚Ð°ÑŽ .txtâ€¦")
        context.user_data["extracted_text"] = read_txt_bytes(bytes(file_bytes))
    else:
        await update.message.reply_text("Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ð½. ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ PDF, DOCX Ð¸Ð»Ð¸ TXT.")
        return

    msg = f"ðŸ“„ Ð¢ÐµÐºÑÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½. Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ð¾Ð²: {len(context.user_data.get('extracted_text',''))}.\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:"
    kb = InlineKeyboardMarkup([
        [InlineKeyboardButton("ðŸ” ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð°", callback_data='analyze_contract')],
        [InlineKeyboardButton("âš ï¸ Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ñ€Ð¸ÑÐºÐ¾Ð²", callback_data='risk_table')],
        [InlineKeyboardButton("ðŸ§¾ ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ¾Ð½Ñ‚Ñ€Ð°Ð³ÐµÐ½Ñ‚Ð° (DD)", callback_data='verify_dd')],
        [InlineKeyboardButton("ðŸ”Ž ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐ¸", callback_data='court_search')],
        [InlineKeyboardButton("âœ‰ï¸ ÐžÑ‚Ð²ÐµÑ‚ Ð½Ð° Ð¿Ñ€ÐµÑ‚ÐµÐ½Ð·Ð¸ÑŽ", callback_data='analyze_claim')],
    ])
    await update.message.reply_text(msg, reply_markup=kb)


async def on_button(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    task = query.data
    text = context.user_data.get("extracted_text") or ""
    if not text:
        await query.edit_message_text("ÐÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð°. ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ PDF/DOCX/TXT.")
        return
    await query.edit_message_text("ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð˜Ð˜â€¦")
    snippet = text if len(text) <= MAX_INPUT_CHARS else text[:MAX_INPUT_CHARS]
    prompt = _build_task_prompt(task, snippet)
    try:
        answer = _llm(prompt)
    except Exception as e:
        log.exception("LLM error")
        answer = f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð·Ð¾Ð²Ð° Ð˜Ð˜: {e}"
    await query.edit_message_text(cut_telegram(answer or "ÐŸÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚."))


def build_app() -> Application:
    if not TELEGRAM_BOT_TOKEN:
        raise RuntimeError("TELEGRAM_BOT_TOKEN Ð½Ðµ Ð·Ð°Ð´Ð°Ð½")
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("diag", cmd_diag))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_any_document))
    app.add_handler(CallbackQueryHandler(on_button))
    return app


def main():
    app = build_app()
    log.info("Bot started (long polling)â€¦")
    app.run_polling()


if __name__ == "__main__":
    main()
